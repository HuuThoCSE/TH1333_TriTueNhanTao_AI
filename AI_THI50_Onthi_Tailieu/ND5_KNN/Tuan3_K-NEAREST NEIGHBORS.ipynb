{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvUKjkDv+4A6vlqU3siLOU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **21022008_NguyenHuuTho**"],"metadata":{"id":"rBW7PF82X8GQ"}},{"cell_type":"markdown","source":["150"],"metadata":{"id":"QWM2hOI7p3M7"}},{"cell_type":"markdown","source":["## Khai báo vài thư viện\n","##### Iris flower dataset có sẵn trong thư viện scikit-learn"],"metadata":{"id":"_qkasPpjX6u5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWmel0ZjWhXN"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import neighbors, datasets"]},{"cell_type":"markdown","source":["Tiếp theo, chúng ta load dữ liệu và hiển thị vài dữ liệu mẫu. Các class được gán nhãn là 0, 1, và 2."],"metadata":{"id":"HtL2ixW5YR-R"}},{"cell_type":"code","source":["iris = datasets.load_iris()\n","iris_X = iris.data\n","iris_y = iris.target\n","print ('Number of classes: %d' %len(np.unique(iris_y)))\n","print ('Number of data points: %d' %len(iris_y))\n","\n","X0 = iris_X[iris_y == 0,:]\n","print ('\\nSamples from class 0:\\n', X0[:5,:])\n","\n","X1 = iris_X[iris_y == 1,:]\n","print ('\\nSamples from class 1:\\n', X1[:5,:])\n","\n","X2 = iris_X[iris_y == 2,:]\n","print ('\\nSamples from class 2:\\n', X2[:5,:])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5SljXj7Wpwn","executionInfo":{"status":"ok","timestamp":1676452560584,"user_tz":-420,"elapsed":573,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"ac383fcb-1b72-462b-9841-4a72985d601c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 3\n","Number of data points: 150\n","\n","Samples from class 0:\n"," [[5.1 3.5 1.4 0.2]\n"," [4.9 3.  1.4 0.2]\n"," [4.7 3.2 1.3 0.2]\n"," [4.6 3.1 1.5 0.2]\n"," [5.  3.6 1.4 0.2]]\n","\n","Samples from class 1:\n"," [[7.  3.2 4.7 1.4]\n"," [6.4 3.2 4.5 1.5]\n"," [6.9 3.1 4.9 1.5]\n"," [5.5 2.3 4.  1.3]\n"," [6.5 2.8 4.6 1.5]]\n","\n","Samples from class 2:\n"," [[6.3 3.3 6.  2.5]\n"," [5.8 2.7 5.1 1.9]\n"," [7.1 3.  5.9 2.1]\n"," [6.3 2.9 5.6 1.8]\n"," [6.5 3.  5.8 2.2]]\n"]}]},{"cell_type":"markdown","source":["##### Nếu nhìn vào vài dữ liệu mẫu, chúng ta thấy rằng hai cột cuối mang khá nhiều thông tin giúp chúng ta có thể phân biệt được chúng.  Chúng ta dự đoán rằng kết quả classification cho cơ sở dữ liệu này sẽ tương đối cao.\n","##### Tách training và test sets, val\n","Giả sử chúng ta muốn dùng 50 điểm dữ liệu cho test set, 100 điểm còn lại cho training set. Scikit-learn có một hàm số cho phép chúng ta ngẫu nhiên lựa chọn các điểm này, như sau:"],"metadata":{"id":"Dfv3amUZYab_"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","     iris_X, iris_y, test_size=50) # Tổng dữ liệu là 150. 50 dùng để test, 100 dùng để train. Câu hỏi: Dùng 30 để test, 120 để train - THI!!!\n","\n","print (\"Training size: %d\" %len(y_train))\n","print (\"Test size    : %d\" %len(y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkkwZcGKWrhA","executionInfo":{"status":"ok","timestamp":1676452710694,"user_tz":-420,"elapsed":2,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"9b1d4e42-236b-41e4-acb9-ddd540958686"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training size: 100\n","Test size    : 50\n"]}]},{"cell_type":"markdown","source":["Sau đây, tôi trước hết xét trường hợp đơn giản K = 1, tức là với mỗi điểm test data, ta chỉ xét 1 điểm training data gần nhất và lấy label của điểm đó để dự đoán cho điểm test này."],"metadata":{"id":"Xu6aTQV5Yj8-"}},{"cell_type":"code","source":["clf = neighbors.KNeighborsClassifier(n_neighbors = 1, p = 2)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","print (\"Print results for 20 test data points:\")\n","print (\"Predicted labels: \", y_pred[20:40])\n","print (\"Ground truth    : \", y_test[20:40])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6a1hddNnWsYl","executionInfo":{"status":"ok","timestamp":1676452713209,"user_tz":-420,"elapsed":2,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"fe7e5955-864b-4a80-c797-05936bd726a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Print results for 20 test data points:\n","Predicted labels:  [2 1 0 0 1 1 2 0 1 2 2 1 1 1 1 2 1 2 2 2]\n","Ground truth    :  [2 1 0 0 1 1 2 0 1 2 2 1 1 1 1 2 2 2 2 2]\n"]}]},{"cell_type":"markdown","source":["Kết quả cho thấy label dự đoán gần giống với label thật của test data, chỉ có 2 điểm trong số 20 điểm được hiển thị có kết quả sai lệch. Ở đây chúng ta làm quen với khái niệm mới: ground truth. Một cách đơn giản, ground truth chính là nhãn/label/đầu ra thực sự của các điểm trong test data. Khái niệm này được dùng nhiều trong Machine Learning, hy vọng lần tới các bạn gặp thì sẽ nhớ ngay nó là gì.\n","Phương pháp đánh giá (evaluation method)\n","Để đánh giá độ chính xác của thuật toán KNN classifier này, chúng ta xem xem có bao nhiêu điểm trong test data được dự đoán đúng. Lấy số lượng này chia cho tổng số lượng trong tập test data sẽ ra độ chính xác. Scikit-learn cung cấp hàm số accuracy_score để thực hiện công việc này."],"metadata":{"id":"sizFTRqkYpeL"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","print (\"Accuracy of 1NN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIMWq7NzWtRH","executionInfo":{"status":"ok","timestamp":1676452722586,"user_tz":-420,"elapsed":3,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"9c4b17bc-28ad-419c-8fcf-0a77837239e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of 1NN: 96.00 %\n"]}]},{"cell_type":"markdown","source":["1NN đã cho chúng ta kết quả là 94%, không tệ! Chú ý rằng đây là một cơ sở dữ liệu dễ vì chỉ với dữ liệu ở hai cột cuối cùng, chúng ta đã có thể suy ra quy luật. Trong ví dụ này, tôi sử dụng p = 2 nghĩa là khoảng cách ở đây được tính là khoảng cách theo norm 2. Các bạn cũng có thể thử bằng cách thay p = 1 cho norm 1, hoặc các giá trị p khác cho norm khác. (Xem thêm sklearn.neighbors.KNeighborsClassifier)\n","Nhận thấy rằng chỉ xét 1 điểm gần nhất có thể dẫn đến kết quả sai nếu điểm đó là nhiễu. Một cách có thể làm tăng độ chính xác là tăng số lượng điểm lân cận lên, ví dụ 10 điểm, và xem xem trong 10 điểm gần nhất, class nào chiếm đa số thì dự đoán kết quả là class đó. Kỹ thuật dựa vào đa số này được gọi là major voting."],"metadata":{"id":"voo5gXe6Y2mE"}},{"cell_type":"code","source":["clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2) # k = 10, n_neighbors = 10. In ra các kết quả từ 5 - 10, chạy dòng for\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","print (\"Accuracy of 10NN with major voting: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpQQdIkwWuLY","executionInfo":{"status":"ok","timestamp":1676452729366,"user_tz":-420,"elapsed":584,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"79ebdaa4-4d40-4bf3-e7ce-2755e93b7fae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of 10NN with major voting: 96.00 %\n"]}]},{"cell_type":"markdown","source":["Đánh trọng số cho các điểm lân cận\n","Là một kẻ tham lam, tôi chưa muốn dừng kết quả ở đây vì thấy rằng mình vẫn có thể cải thiện được. Trong kỹ thuật major voting bên trên, mỗi trong 10 điểm gần nhất được coi là có vai trò như nhau và giá trị lá phiếu của mỗi điểm này là như nhau. Tôi cho rằng như thế là không công bằng, vì rõ ràng rằng những điểm gần hơn nên có trọng số cao hơn (càng thân cận thì càng tin tưởng). Cách đánh trọng số phải thỏa mãn điều kiện là một điểm càng gần điểm test data thì phải được đánh trọng số càng cao (tin tưởng hơn). Cách đơn giản nhất là lấy nghịch đảo của khoảng cách này. (Trong trường hợp test data trùng với 1 điểm dữ liệu trong training data, tức khoảng cách bằng 0, ta lấy luôn label của điểm training data).\n","Scikit-learn giúp chúng ta đơn giản hóa việc này bằng cách gán giá trị weights = 'distance'. (Giá trị mặc định của weights là 'uniform', tương ứng với việc coi tất cả các điểm lân cận có giá trị như nhau như ở trên)."],"metadata":{"id":"eQ3a08nfY4xW"}},{"cell_type":"code","source":["clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance')\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","print (\"Accuracy of 10NN (1/distance weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3iUqDG7Wu-b","executionInfo":{"status":"ok","timestamp":1676452736650,"user_tz":-420,"elapsed":2,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"a71fc7b6-88ae-4581-8b99-1c275de1e2ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of 10NN (1/distance weights): 98.00 %\n"]}]},{"cell_type":"markdown","source":["Chú ý: Ngoài 2 phương pháp đánh trọng số weights = 'uniform' và weights = 'distance' ở trên, scikit-learn còn cung cấp cho chúng ta một cách để đánh trọng số một cách tùy chọn. Ví dụ, một cách đánh trọng số phổ biến khác trong Machine Learning là:\n","wi=exp(−||x−xi||22σ2)wi=exp⁡(−||x−xi||22σ2)\n","trong đó xx là test data, xixi là một điểm trong K-lân cận của xx, wiwi là trọng số của điểm đó (ứng với điểm dữ liệu đang xét xx), σσ là một số dương. Nhận thấy rằng hàm số này cũng thỏa mãn điều kiện: điểm càng gần xx thì trọng số càng cao (cao nhất bằng 1). Với hàm số này, chúng ta có thể lập trình như sau:"],"metadata":{"id":"uFhX9a1-Y6Vn"}},{"cell_type":"code","source":["def myweight(distances):\n","    sigma2 = .5 # we can change this number\n","    return np.exp(-distances**2/sigma2)\n","\n","clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = myweight)\n","clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","print (\"Accuracy of 10NN (customized weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NOvfp1TDWv17","executionInfo":{"status":"ok","timestamp":1676452742186,"user_tz":-420,"elapsed":3,"user":{"displayName":"Huu Tho Nguyen","userId":"16998784333720908057"}},"outputId":"6fd465e0-1c9c-4f16-d555-f8c1438c09a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of 10NN (customized weights): 98.00 %\n"]}]},{"cell_type":"markdown","source":["Trong trường hợp này, kết quả tương đương với kỹ thuật major voting. Để đánh giá chính xác hơn kết quả của KNN với K khác nhau, cách định nghĩa khoảng cách khác nhau và cách đánh trọng số khác nhau, chúng ta cần thực hiện quá trình trên với nhiều cách chia dữ liệu training và test khác nhau rồi lấy kết quả trung bình, vì rất có thể dữ liệu phân chia trong 1 trường hợp cụ thể là rất tốt hoặc rất xấu (bias). Đây cũng là cách thường được dùng khi đánh giá hiệu năng của một thuật toán cụ thể nào đó."],"metadata":{"id":"fYHsX_kWY9s3"}}]}